{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\pabma\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: emoji in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from stanza) (2.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from stanza) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from stanza) (4.25.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from stanza) (2.31.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from stanza) (2.1.1+cu121)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from stanza) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from requests->stanza) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from requests->stanza) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pabma\\anaconda3\\lib\\site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "import torch\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f63769c7f1d458ca8c102739fa52a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 20:28:49 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-11-25 20:28:50 INFO: File exists: C:\\Users\\pabma\\stanza_resources\\en\\default.zip\n",
      "2023-11-25 20:28:53 INFO: Finished downloading models and saved to C:\\Users\\pabma\\stanza_resources.\n",
      "2023-11-25 20:28:53 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6e8657cb4e4cdaacb07a79cf9b0798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 20:28:54 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-11-25 20:28:54 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2023-11-25 20:28:54 INFO: Using device: cuda\n",
      "2023-11-25 20:28:54 INFO: Loading: tokenize\n",
      "2023-11-25 20:28:54 INFO: Loading: pos\n",
      "2023-11-25 20:28:55 INFO: Loading: lemma\n",
      "2023-11-25 20:28:55 INFO: Loading: depparse\n",
      "2023-11-25 20:28:55 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Download and set up the Stanza pipeline\n",
    "stanza.download('en')  # for English\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def evaluate_syntax_fluency(sentence):\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    if len(doc) == 0:\n",
    "        return 0.0  # Empty sentence\n",
    "\n",
    "    num_tokens = len(doc)\n",
    "    if num_tokens <= 2:  # Penalize very short or fragmentary sentences\n",
    "        return 0.5\n",
    "\n",
    "    tree_depths = []\n",
    "    unique_dependency_types = set()\n",
    "\n",
    "    for token in doc:\n",
    "        # Calculate depth of each token in the parse tree\n",
    "        depth = 0\n",
    "        current_token = token\n",
    "        while current_token.head != current_token:\n",
    "            depth += 1\n",
    "            current_token = current_token.head\n",
    "        tree_depths.append(depth)\n",
    "\n",
    "        # Collect unique dependency types\n",
    "        unique_dependency_types.add(token.dep_)\n",
    "\n",
    "    # Metrics\n",
    "    max_depth = max(tree_depths)\n",
    "    depth_variety_score = len(unique_dependency_types) / num_tokens\n",
    "\n",
    "    # Score calculation (adjusted heuristic)\n",
    "    # Higher max depth might indicate complexity (lower fluency)\n",
    "    # More variety in dependency types might indicate richer syntactic structure (higher fluency)\n",
    "    fluency_score = (1 - (max_depth / (2 * num_tokens)) + depth_variety_score) / 2\n",
    "\n",
    "    return fluency_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Syntax Fluency Score: 0.77\n",
      "\n",
      "Sentence: While the fox jumps, the dog barks.\n",
      "Syntax Fluency Score: 0.81\n",
      "\n",
      "Sentence: Fox.\n",
      "Syntax Fluency Score: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"While the fox jumps, the dog barks.\",\n",
    "    \"Fox.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    fluency_score = evaluate_syntax_fluency(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Syntax Fluency Score: {fluency_score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_yes_no_question(question):\n",
    "    question = question.lower().strip()\n",
    "    if question.startswith(('is', 'are', 'do', 'does', 'did', 'was', 'were', 'will', 'can', 'could', 'should', 'have', 'has', 'had')):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_yes_no_answer(answer):\n",
    "    answer = answer.lower().strip()\n",
    "    if answer.startswith(('yes','no')):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Is this right?\n",
      "Is yes/no type question: 1.00\n",
      "\n",
      "Sentence: Which questions are you thinking of?\n",
      "Is yes/no type question: 0.00\n",
      "\n",
      "Sentence: Fox.\n",
      "Is yes/no type question: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "sentences = [\n",
    "    \"Is this right?\",\n",
    "    \"Which questions are you thinking of?\",\n",
    "    \"Fox.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    is_yes_no = is_yes_no_question(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Is yes/no type question: {is_yes_no:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load the spaCy model for linguistic features\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def evaluate_conciseness(answer):\n",
    "    # Tokenize the answer and analyze with spaCy\n",
    "    doc = nlp(answer)\n",
    "    word_count = len(word_tokenize(answer))\n",
    "\n",
    "    # Calculate the ratio of content words (nouns, verbs, adjectives, adverbs) to total words\n",
    "    content_words_count = sum(token.pos in [spacy.symbols.NOUN, spacy.symbols.VERB, spacy.symbols.ADJ, spacy.symbols.ADV] for token in doc)\n",
    "    content_ratio = content_words_count / word_count if word_count else 0\n",
    "\n",
    "    # Conciseness favors higher content ratio (more information with fewer words)\n",
    "    conciseness_score = content_ratio\n",
    "\n",
    "    # Adjusting score for extremely short answers\n",
    "    # Extremely short answers (like 'yes' or 'no') are typically very concise\n",
    "    if word_count <= 2:\n",
    "        conciseness_score = max(conciseness_score, 0.9)\n",
    "\n",
    "    # Adjusting score to be between 0 and 1\n",
    "    conciseness_score = max(0, min(conciseness_score, 1))\n",
    "\n",
    "    return conciseness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes.\n",
      "Conciseness Score: 0.90\n",
      "\n",
      "Answer: The cat sat on the mat.\n",
      "Conciseness Score: 0.43\n",
      "\n",
      "Answer: This is a somewhat more elaborative answer providing detailed information, albeit not necessarily in a concise manner.\n",
      "Conciseness Score: 0.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "answers = [\n",
    "    \"Yes.\",\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"This is a somewhat more elaborative answer providing detailed information, albeit not necessarily in a concise manner.\"\n",
    "]\n",
    "\n",
    "for answer in answers:\n",
    "    score = evaluate_conciseness(answer)\n",
    "    print(f\"Answer: {answer}\\nConciseness Score: {score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntactic_score(question,answer):\n",
    "    coherency = 1 if is_yes_no_question(question) == is_yes_no_answer(answer) else 0\n",
    "    fluency=evaluate_syntax_fluency(answer)\n",
    "    conciseness=evaluate_conciseness(answer)\n",
    "    syntactic_score=(coherency+fluency+conciseness)/3\n",
    "    return syntactic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples putting it all together\n",
    "questions=['Are dogs pets?',\n",
    "           'Is a dog a pet?',\n",
    "\n",
    "           'Is it Saturday',\n",
    "           'What day is it?',\n",
    "\n",
    "           'Where are you going?',\n",
    "           'Are you goind downtown?',\n",
    "\n",
    "           'Did you forget?',\n",
    "           'Have you forgotten?',\n",
    "\n",
    "           'How long has it been?',\n",
    "           'Has it been long?'\n",
    "           ]\n",
    "\n",
    "answers=['I dont know',\n",
    "         'Yes it is',\n",
    "\n",
    "         'It is not Saturday',\n",
    "         'No',\n",
    "\n",
    "         'Nowhere, stop asking',\n",
    "         'YES!',\n",
    "         \n",
    "         'Maybe I did',\n",
    "         'No. Stop bothering',\n",
    "\n",
    "         'Its been very long since we last spoke',\n",
    "         'No, not really']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Are dogs pets? |A: I dont know |SYNTACTIC SCORE: 0.4236111111111111 \n",
      "\n",
      "Q: Is a dog a pet? |A: Yes it is |SYNTACTIC SCORE: 0.638888888888889 \n",
      "\n",
      "Q: Is it Saturday |A: It is not Saturday |SYNTACTIC SCORE: 0.3125 \n",
      "\n",
      "Q: What day is it? |A: No |SYNTACTIC SCORE: 0.4666666666666666 \n",
      "\n",
      "Q: Where are you going? |A: Nowhere, stop asking |SYNTACTIC SCORE: 0.5625 \n",
      "\n",
      "Q: Are you goind downtown? |A: YES! |SYNTACTIC SCORE: 0.7999999999999999 \n",
      "\n",
      "Q: Did you forget? |A: Maybe I did |SYNTACTIC SCORE: 0.5277777777777778 \n",
      "\n",
      "Q: Have you forgotten? |A: No. Stop bothering |SYNTACTIC SCORE: 0.8958333333333334 \n",
      "\n",
      "Q: How long has it been? |A: Its been very long since we last spoke |SYNTACTIC SCORE: 0.7708333333333334 \n",
      "\n",
      "Q: Has it been long? |A: No, not really |SYNTACTIC SCORE: 0.7083333333333334 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "for i in range(len(questions)):\n",
    "    syntactic_score_=syntactic_score(questions[i],answers[i])\n",
    "    print('Q:',questions[i],'|A:',answers[i],'|SYNTACTIC SCORE:',syntactic_score_ , '\\n' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Are dogs pets? |YES/NO? 1 ||A: I dont know |COHERENCY: 0 |FLUENCY: 0.9375 |CONCISENESS: 0.3333333333333333 ||SYNTACTIC SCORE: 0.4236111111111111 \n",
      "\n",
      "Q: Is a dog a pet? |YES/NO? 1 ||A: Yes it is |COHERENCY: 1 |FLUENCY: 0.9166666666666667 |CONCISENESS: 0 ||SYNTACTIC SCORE: 0.638888888888889 \n",
      "\n",
      "Q: Is it Saturday |YES/NO? 1 ||A: It is not Saturday |COHERENCY: 0 |FLUENCY: 0.9375 |CONCISENESS: 0 ||SYNTACTIC SCORE: 0.3125 \n",
      "\n",
      "Q: What day is it? |YES/NO? 0 ||A: No |COHERENCY: 0 |FLUENCY: 0.5 |CONCISENESS: 0.9 ||SYNTACTIC SCORE: 0.4666666666666666 \n",
      "\n",
      "Q: Where are you going? |YES/NO? 0 ||A: Nowhere, stop asking |COHERENCY: 0 |FLUENCY: 0.9375 |CONCISENESS: 0.75 ||SYNTACTIC SCORE: 0.5625 \n",
      "\n",
      "Q: Are you goind downtown? |YES/NO? 1 ||A: YES! |COHERENCY: 1 |FLUENCY: 0.5 |CONCISENESS: 0.9 ||SYNTACTIC SCORE: 0.7999999999999999 \n",
      "\n",
      "Q: Did you forget? |YES/NO? 1 ||A: Maybe I did |COHERENCY: 0 |FLUENCY: 0.9166666666666667 |CONCISENESS: 0.6666666666666666 ||SYNTACTIC SCORE: 0.5277777777777778 \n",
      "\n",
      "Q: Have you forgotten? |YES/NO? 1 ||A: No. Stop bothering |COHERENCY: 1 |FLUENCY: 0.9375 |CONCISENESS: 0.75 ||SYNTACTIC SCORE: 0.8958333333333334 \n",
      "\n",
      "Q: How long has it been? |YES/NO? 0 ||A: Its been very long since we last spoke |COHERENCY: 1 |FLUENCY: 0.8125 |CONCISENESS: 0.5 ||SYNTACTIC SCORE: 0.7708333333333334 \n",
      "\n",
      "Q: Has it been long? |YES/NO? 1 ||A: No, not really |COHERENCY: 1 |FLUENCY: 0.875 |CONCISENESS: 0.25 ||SYNTACTIC SCORE: 0.7083333333333334 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question classifier\n",
    "\n",
    "for i in range(len(questions)):\n",
    "\n",
    "    coherency = 1 if is_yes_no_question(questions[i]) == is_yes_no_answer(answers[i]) else 0\n",
    "    fluency=evaluate_syntax_fluency(answers[i])\n",
    "    conciseness=evaluate_conciseness(answers[i])\n",
    "    syntactic_score=(coherency+fluency+conciseness)/3\n",
    "\n",
    "    print('Q:',questions[i],'|YES/NO?',is_yes_no_question(questions[i]), '||A:',answers[i],'|COHERENCY:',coherency, '|FLUENCY:', fluency, '|CONCISENESS:',conciseness,'||SYNTACTIC SCORE:',syntactic_score , '\\n' ) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
